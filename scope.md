## Ubundi Trial Project: Build a Personal Codex Agent

### Objective

Build a context-aware agent that can answer questions about *you* as a candidate—based on documents and data you’ve created.

This trial tests your ability to work AI-natively, structure unstructured data, and build something useful and expressive in a short time.

### What to Build

Create a chatbot or agent that answers questions like:

* “What kind of engineer are you?”  
* “What are your strongest technical skills?”  
* “What projects or experiences are you most proud of?”  
* “What do you value in a team or company culture?”  
* “What’s your approach to learning or debugging something new?”

The agent should speak in your voice and refer to the materials you include. It should feel like a lightweight, first version of your own Codex.

### Inputs

Provide the following as your "training data":

* Your CV/resume (PDF, markdown, or plain text)  
* At least 2–3 supporting documents, such as:  
  * Blog posts or personal website content  
  * README files or documentation you’ve written  
  * Snippets of code with thoughtful comments  
  * Notes, essays, or transcripts (e.g., a short voice memo about your work style or values)

Organize your content clearly. It doesn’t need to be perfect—just authentic and expressive.

### Requirements

* Use of RAG (retrieval-augmented generation) is optional but recommended  
  * If you do not use RAG, please include a short note explaining how you would extend your agent to use RAG in the future  
* Deploy a simple UI where we can interact with your chatbot or agent (use any of Replit, Streamlit, Vercel, etc)  
* Include a README that explains:  
  * Your system setup and design choices  
  * Sample questions and expected answers  
  * What you’d improve with more time

### Show Your Thinking

We strongly encourage you to use AI coding agents (e.g., GitHub Copilot, GPT-4, Claude, Cursor, or others) in the process of building your project.

As part of your submission, please include:

* The artifacts and building blocks you used or created while collaborating with AI agents (e.g., prompt history, agent instructions, context definitions)  
* Any sub-agents you defined or delegated tasks to (what they were responsible for, how you scoped their role)  
* Your instructions, rules, or guidance to these agents—as this helps us understand your thinking process

These artifacts are the closest representation of how you think, problem-solve, and build in an AI-native workflow.

### Bonus Features (Optional)

These are completely optional stretch goals. You're not expected to complete them all. Tackling even one thoughtfully can set you apart and show depth. Be mindful of time—only explore these if you're feeling inspired or want to show off something you're proud of.

* Add a self-reflective agent mode to answer:  
  * “What kind of tasks energize or drain me?”  
  * “How do I collaborate best with others?”  
  * “Where do I need to grow?”  
* Add a way to extend or update the dataset easily  
* Add a tone/mode switcher, for example:  
  * “Interview mode” (answers are concise, professional, and informative—designed for someone evaluating you)  
  * “Personal storytelling mode” (answers are longer, more reflective, and narrative in tone)  
  * “Fast facts mode” (answers in bullet points or TL;DR format)  
  * “Humble brag mode” (answers with confidence and self-promotion turned up a notch—still grounded in truth)  
  * Feel free to invent other modes you think are interesting or useful.  
* Use creative prompt strategies or agent chaining

### Time Budget

Aim to spend no more than 6-8 hours. We’re not looking for a full app—we’re looking for how you think, structure, and prototype.

### Stipend

To cover token costs and dev tools, we provide a R1000 stipend to shortlisted candidates who complete the project. This is a gesture of good faith, not compensation.

Evaluation Criteria

| Criteria | What We’re Looking For |
| :---- | :---- |
| **Context handling** | Did you build around personal data in a structured and meaningful way? |
| **Agentic thinking** | Did you design it with personality, modes, or interactivity in mind? |
| **Use of personal data** | Is your dataset thoughtful and representative of who you are? |
| **Build quality** | Can we run it, test it, and understand how it works? |
| **Voice & reflection** | Does it feel like *you*? Can we learn something real and unique about you? |
| **Bonus effort** | Polish, creativity, useful surprises |
| **AI build artifacts** | Did you show how you collaborated with coding agents? |
| **(Optional) RAG usage** | If used, was it implemented effectively? If not, did you explain how you would? |

### 

### Submission

Please share:

* A link to your GitHub repo (this should include your full project files, documentation, and your "Show Your Thinking" artifacts—prompt histories, agent instructions, sub-agent roles, etc.)  
* A link to your deployed chatbot or agent via any online-accessible platform (Replit, Streamlit, Vercel, or similar)  
* A short video walkthrough (max 5 mins) explaining your project  
* Anything else you want us to see or read

